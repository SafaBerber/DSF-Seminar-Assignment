{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2018] Filings columns: ['year', 'company', 'cik', 'form_type', 'date_filed', 'url', 'document_url']\n",
      "[2018] S&P columns: ['company', 'ticker', 'cik', 'sector']\n",
      "[2018] ✅ Saved: Data/sp500_10k_links/filtered_10K_filings_2018.csv with 444 rows\n",
      "\n",
      "[2019] Filings columns: ['year', 'company', 'cik', 'form_type', 'date_filed', 'document_url']\n",
      "[2019] S&P columns: ['company', 'ticker', 'cik', 'sector']\n",
      "[2019] ✅ Saved: Data/sp500_10k_links/filtered_10K_filings_2019.csv with 445 rows\n",
      "\n",
      "[2020] Filings columns: ['year', 'company', 'cik', 'form_type', 'date_filed', 'url', 'document_url']\n",
      "[2020] S&P columns: ['company', 'ticker', 'cik', 'sector']\n",
      "[2020] ✅ Saved: Data/sp500_10k_links/filtered_10K_filings_2020.csv with 445 rows\n",
      "\n",
      "[2021] Filings columns: ['year', 'company', 'cik', 'form_type', 'date_filed', 'url', 'document_url']\n",
      "[2021] S&P columns: ['company', 'ticker', 'cik', 'sector']\n",
      "[2021] ✅ Saved: Data/sp500_10k_links/filtered_10K_filings_2021.csv with 440 rows\n",
      "\n",
      "[2022] Filings columns: ['year', 'company', 'cik', 'form_type', 'date_filed', 'url', 'document_url']\n",
      "[2022] S&P columns: ['company', 'ticker', 'cik', 'sector']\n",
      "[2022] ✅ Saved: Data/sp500_10k_links/filtered_10K_filings_2022.csv with 436 rows\n",
      "\n",
      "[2023] Filings columns: ['year', 'company', 'cik', 'form_type', 'date_filed', 'url', 'document_url']\n",
      "[2023] S&P columns: ['company', 'ticker', 'cik', 'sector']\n",
      "[2023] ✅ Saved: Data/sp500_10k_links/filtered_10K_filings_2023.csv with 444 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Base folders\n",
    "filings_folder = \"Data/10k_fillings_links\"\n",
    "sp500_folder = \"Data/sp500\"\n",
    "output_folder = \"Data/sp500_10k_links\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "years = range(2018, 2024)\n",
    "\n",
    "for year in years:\n",
    "    try:\n",
    "        filings_path = os.path.join(filings_folder, f\"10K_filings_{year+1}_with_links.csv\")\n",
    "        sp500_path = os.path.join(sp500_folder, f\"sp500_full_{year}.csv\")\n",
    "        output_path = os.path.join(output_folder, f\"filtered_10K_filings_{year}.csv\")\n",
    "\n",
    "        # Try parsing with comma, fallback to semicolon if needed\n",
    "        try:\n",
    "            filings_df = pd.read_csv(filings_path, sep=',', engine='python', on_bad_lines='skip')\n",
    "            if len(filings_df.columns) == 1:\n",
    "                raise ValueError(\"Single column detected, retrying with semicolon separator...\")\n",
    "        except:\n",
    "            filings_df = pd.read_csv(filings_path, sep=';', engine='python', on_bad_lines='skip')\n",
    "\n",
    "        # Clean up column names\n",
    "        filings_df.columns = filings_df.columns.str.strip().str.lower()\n",
    "\n",
    "        # Load and clean S&P 500 CSV\n",
    "        sp500_df = pd.read_csv(sp500_path)\n",
    "        sp500_df.columns = sp500_df.columns.str.strip().str.lower()\n",
    "\n",
    "        print(f\"\\n[{year}] Filings columns: {filings_df.columns.tolist()}\")\n",
    "        print(f\"[{year}] S&P columns: {sp500_df.columns.tolist()}\")\n",
    "\n",
    "        # Ensure CIK column is present\n",
    "        if 'cik' not in filings_df.columns or 'cik' not in sp500_df.columns:\n",
    "            print(f\"[{year}] Skipping: 'cik' column not found.\")\n",
    "            continue\n",
    "\n",
    "        # Normalize CIKs \n",
    "        filings_df['cik_clean'] = filings_df['cik'].astype(str).str.strip().str.replace(r'\\.0$', '', regex=True)\n",
    "        sp500_df['cik_clean'] = sp500_df['cik'].astype(str).str.strip().str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "        # Filter by CIK \n",
    "        filtered_df = filings_df[filings_df['cik_clean'].isin(sp500_df['cik_clean'])].copy()\n",
    "        filtered_df.drop(columns=['cik_clean'], inplace=True)\n",
    "\n",
    "        filtered_df.to_csv(output_path, index=False)\n",
    "        print(f\"[{year}] ✅ Saved: {output_path} with {len(filtered_df)} rows\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[{year}] ❌ Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
